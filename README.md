# Decision-Trees-Random-Forests-Heart-Disease-Prediction


### Objective:
Train and compare tree-based models to classify heart disease presence.

### Models Used:
- Decision Tree (max_depth=4)
- Random Forest (100 trees)

### Tools:
- Python, Scikit-learn, Matplotlib, Seaborn

### Key Results:
- Decision Tree Accuracy: 80%
- Random Forest Accuracy: 87%
- Random Forest had higher accuracy and more generalization.
- Important features: 'thalach', 'cp', 'oldpeak', 'chol'

### Insights:
- Controlling tree depth reduces overfitting.
- Random Forests reduce variance and improve stability.
- Feature importance helps interpret model behavior.

### What I Learned:
- How to visualize decision paths in a tree
- How ensemble models like Random Forests improve performance
- How to interpret model predictions using feature importances

